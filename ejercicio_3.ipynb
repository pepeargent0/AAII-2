{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T19:54:24.264728Z",
     "start_time": "2024-10-19T19:52:40.166358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "# Descargar el dataset desde Google Drive\n",
    "url = \"https://drive.google.com/uc?id=1Pqs5Y6dZr4R66Dby5hIUIjPZtBI28rmJ\"\n",
    "gdown.download(url, \"natural_scenes.zip\", quiet=False)\n",
    "\n",
    "# Descomprimir el dataset\n",
    "with zipfile.ZipFile(\"natural_scenes.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"natural_scenes\")\n"
   ],
   "id": "ec854bb52688bdc3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Pqs5Y6dZr4R66Dby5hIUIjPZtBI28rmJ\n",
      "From (redirected): https://drive.google.com/uc?id=1Pqs5Y6dZr4R66Dby5hIUIjPZtBI28rmJ&confirm=t&uuid=2e84f744-a82f-45c6-9b8b-0217368849e7\n",
      "To: /Users/pepeargentoo/AAII-2/natural_scenes.zip\n",
      "100%|██████████| 363M/363M [01:30<00:00, 4.00MB/s] \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T20:01:42.602871Z",
     "start_time": "2024-10-19T20:01:41.752215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Definición de generadores de datos con aumento y normalización\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flujo de datos de entrenamiento y validación desde la carpeta correcta\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"natural_scenes/seg_train/seg_train\", target_size=(150, 150), batch_size=32,\n",
    "    class_mode='categorical', subset='training')\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    \"natural_scenes/seg_train/seg_train\", target_size=(150, 150), batch_size=32,\n",
    "    class_mode='categorical', subset='validation')\n",
    "\n",
    "# Flujo de datos de prueba\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"natural_scenes/seg_test/seg_test\", target_size=(150, 150), batch_size=32,\n",
    "    class_mode='categorical')\n"
   ],
   "id": "be4af787cc246ec6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11230 images belonging to 6 classes.\n",
      "Found 2804 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T20:21:25.189428Z",
     "start_time": "2024-10-19T20:03:19.108858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model_cnn = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_cnn.fit(train_generator, validation_data=val_generator, epochs=10)\n"
   ],
   "id": "8a56856f752cd65e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pepeargentoo/AAII-2/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/pepeargentoo/AAII-2/.venv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m107s\u001B[0m 302ms/step - accuracy: 0.5139 - loss: 1.5409 - val_accuracy: 0.7536 - val_loss: 0.6911\n",
      "Epoch 2/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m111s\u001B[0m 315ms/step - accuracy: 0.7670 - loss: 0.6506 - val_accuracy: 0.7539 - val_loss: 0.6814\n",
      "Epoch 3/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m110s\u001B[0m 312ms/step - accuracy: 0.8467 - loss: 0.4342 - val_accuracy: 0.7721 - val_loss: 0.6491\n",
      "Epoch 4/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m108s\u001B[0m 306ms/step - accuracy: 0.9273 - loss: 0.2309 - val_accuracy: 0.7710 - val_loss: 0.7883\n",
      "Epoch 5/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m108s\u001B[0m 309ms/step - accuracy: 0.9652 - loss: 0.1141 - val_accuracy: 0.7907 - val_loss: 0.8249\n",
      "Epoch 6/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m110s\u001B[0m 313ms/step - accuracy: 0.9887 - loss: 0.0508 - val_accuracy: 0.7889 - val_loss: 0.8621\n",
      "Epoch 7/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m110s\u001B[0m 312ms/step - accuracy: 0.9935 - loss: 0.0310 - val_accuracy: 0.7832 - val_loss: 0.9858\n",
      "Epoch 8/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m107s\u001B[0m 306ms/step - accuracy: 0.9893 - loss: 0.0414 - val_accuracy: 0.7839 - val_loss: 1.0670\n",
      "Epoch 9/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m108s\u001B[0m 309ms/step - accuracy: 0.9939 - loss: 0.0293 - val_accuracy: 0.7800 - val_loss: 1.0288\n",
      "Epoch 10/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m108s\u001B[0m 306ms/step - accuracy: 0.9912 - loss: 0.0310 - val_accuracy: 0.7347 - val_loss: 1.3153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x143c28ac0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-19T20:23:13.503097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Add, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x):\n",
    "    skip = x\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    return Add()([x, skip])\n",
    "\n",
    "inputs = Input(shape=(150, 150, 3))\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = residual_block(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "outputs = Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_residual = Model(inputs, outputs)\n",
    "model_residual.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_residual.fit(train_generator, validation_data=val_generator, epochs=10)\n"
   ],
   "id": "64c21b9a759b3bca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m712s\u001B[0m 2s/step - accuracy: 0.5219 - loss: 3.7659 - val_accuracy: 0.7325 - val_loss: 0.7301\n",
      "Epoch 2/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m710s\u001B[0m 2s/step - accuracy: 0.8160 - loss: 0.5312 - val_accuracy: 0.7386 - val_loss: 0.7330\n",
      "Epoch 3/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m713s\u001B[0m 2s/step - accuracy: 0.9294 - loss: 0.2367 - val_accuracy: 0.7507 - val_loss: 0.8234\n",
      "Epoch 4/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m716s\u001B[0m 2s/step - accuracy: 0.9705 - loss: 0.1054 - val_accuracy: 0.7404 - val_loss: 0.8923\n",
      "Epoch 5/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m708s\u001B[0m 2s/step - accuracy: 0.9868 - loss: 0.0650 - val_accuracy: 0.7429 - val_loss: 1.1448\n",
      "Epoch 6/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m710s\u001B[0m 2s/step - accuracy: 0.9927 - loss: 0.0439 - val_accuracy: 0.7507 - val_loss: 1.0489\n",
      "Epoch 7/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m713s\u001B[0m 2s/step - accuracy: 0.9955 - loss: 0.0296 - val_accuracy: 0.7268 - val_loss: 1.3168\n",
      "Epoch 8/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m715s\u001B[0m 2s/step - accuracy: 0.9924 - loss: 0.0387 - val_accuracy: 0.7379 - val_loss: 1.2636\n",
      "Epoch 9/10\n",
      "\u001B[1m164/351\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m6:03\u001B[0m 2s/step - accuracy: 0.9967 - loss: 0.0392"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False  # Congelar las capas base\n",
    "\n",
    "model_transfer = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model_transfer.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_transfer.fit(train_generator, validation_data=val_generator, epochs=10)\n"
   ],
   "id": "f22cac9f28b7030",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluar cada modelo en el conjunto de prueba\n",
    "print(\"Evaluación Modelo Denso:\")\n",
    "model_dense.evaluate(test_generator)\n",
    "\n",
    "print(\"Evaluación Modelo CNN:\")\n",
    "model_cnn.evaluate(test_generator)\n",
    "\n",
    "print(\"Evaluación Modelo Residual:\")\n",
    "model_residual.evaluate(test_generator)\n",
    "\n",
    "print(\"Evaluación Transfer Learning:\")\n",
    "model_transfer.evaluate(test_generator)\n"
   ],
   "id": "525695dafa66802d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3db85b2022a71c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
